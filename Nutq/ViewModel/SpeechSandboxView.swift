//
//  SpeechSandboxView.swift
//  Nutq
//
//  Created by Rahaf Alhammadi on 16/06/1447 AH.
//

import SwiftUI

struct SpeechSandboxView: View {
    @StateObject private var speechService = SpeechRecognizerService()
    
    // We store only the symbol (e.g. "Ø¨") to avoid any Hashable / Identifiable issues
    @State private var targetLetterSymbol: String = ArabicAlphabet.all.first?.symbol ?? "Ø£"
    
    // The letter we *think* the user said
    @State private var detectedLetter: Letter?
    
    // Helper to get the full target Letter from its symbol
    private var targetLetter: Letter? {
        ArabicAlphabet.all.first { $0.symbol == targetLetterSymbol }
    }
    
    var body: some View {
        VStack(spacing: 24) {
            Text("ðŸŽ¤ Speech Sandbox")
                .font(.title2.bold())
            
            // 1) Choose target letter
            VStack(spacing: 8) {
                Text("Target letter (what you asked for):")
                    .font(.subheadline)
                
                Picker("Letter", selection: $targetLetterSymbol) {
                    ForEach(ArabicAlphabet.all, id: \.symbol) { letter in
                        Text("\(letter.symbol)  -  \(letter.name)")
                            .tag(letter.symbol)
                    }
                }
                .labelsHidden()
                .pickerStyle(.wheel)
                .frame(height: 120)
            }
            .padding()
            .background(.ultraThinMaterial)
            .clipShape(RoundedRectangle(cornerRadius: 20))
            
            // 2) Mic button
            Button(action: {
                let wasRecording = speechService.isRecording
                
                // Toggle recording
                speechService.toggleRecording()
                
                if !wasRecording {
                    // We just STARTED recording â†’ clear previous result
                    detectedLetter = nil
                }
            }) {
                ZStack {
                    Circle()
                        .fill(speechService.isRecording ? Color.red.opacity(0.7) : Color.green.opacity(0.7))
                        .frame(width: 90, height: 90)
                    
                    Image(systemName: speechService.isRecording ? "stop.fill" : "mic.fill")
                        .font(.system(size: 32, weight: .bold))
                        .foregroundColor(.white)
                }
            }
            
            // 3) Show transcript
            VStack(alignment: .leading, spacing: 8) {
                Text("Transcript:")
                    .font(.subheadline.bold())
                
                Text(speechService.transcript.isEmpty ? "Say the letter nameâ€¦" : speechService.transcript)
                    .frame(maxWidth: .infinity, alignment: .leading)
                    .padding()
                    .background(Color.black.opacity(0.05))
                    .clipShape(RoundedRectangle(cornerRadius: 12))
            }
            .padding(.horizontal)
            
            // 4) Show detection result
            VStack(spacing: 8) {
                Text("Detected letter:")
                    .font(.subheadline.bold())
                
                if let detected = detectedLetter {
                    Text("\(detected.symbol) â€“ \(detected.name)")
                        .font(.title3.bold())
                    
                    if let target = targetLetter, detected.symbol == target.symbol {
                        Text("âœ… Ø£Ø­Ø³Ù†Øª! Ù†Ø·Ù‚ØªÙ Ø§Ù„Ø­Ø±Ù Ø§Ù„ØµØ­ÙŠØ­ ðŸŒŸ")
                            .foregroundColor(.green)
                    } else if let target = targetLetter {
                        Text("âŒ Ø§Ù„Ø­Ø±Ù Ù…Ø®ØªÙ„Ù.\nØ§Ù„Ù…Ø·Ù„ÙˆØ¨: \(target.symbol) â€“ \(target.name)")
                            .multilineTextAlignment(.center)
                            .foregroundColor(.red)
                    } else {
                        Text("ØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø­Ø±Ù Ù„ÙƒÙ† Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø­Ø±Ù Ù…Ø³ØªÙ‡Ø¯Ù Ù…Ø­Ø¯Ø¯.")
                            .foregroundColor(.orange)
                    }
                } else {
                    if !speechService.transcript.isEmpty {
                        Text("ðŸ¤” Ù„Ù… Ø£Ø³ØªØ·Ø¹ Ù…Ø¹Ø±ÙØ© Ø£ÙŠ Ø­Ø±Ù Ù…Ù† Ø§Ù„ÙƒÙ„Ø§Ù….")
                            .foregroundColor(.secondary)
                    } else {
                        Text("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø­Ø±Ù Ø¨Ø¹Ø¯.\nØ§Ø®ØªØ§Ø±ÙŠ Ø­Ø±Ù ÙˆØ§Ø¶ØºØ·ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ø«Ù… Ø§Ù†Ø·Ù‚ÙŠ Ø§Ø³Ù…Ù‡.")
                            .multilineTextAlignment(.center)
                            .foregroundColor(.secondary)
                    }
                }
            }
            .padding()
            .frame(maxWidth: .infinity)
            .background(.ultraThinMaterial)
            .clipShape(RoundedRectangle(cornerRadius: 20))
            .padding(.horizontal)
            
            Spacer()
        }
        .padding()
        // ðŸ‘‡ðŸ‘‡ THIS is the live-feedback part
        .onChange(of: speechService.transcript) { newValue in
            // Only care while recording
            guard speechService.isRecording else { return }
            
            // Try to detect letter from the current transcript
            detectedLetter = detectLetter(from: newValue)
            print("ðŸŽ§ Live transcript:", newValue)
        }
    }
}

// MARK: - Detection helper
extension SpeechSandboxView {
    /// Super simple detection:
    /// - checks if transcript contains the letter symbol (e.g. "Ø¨")
    /// - or the letter name (e.g. "Ø¨Ø§Ø¡")
    func detectLetter(from transcript: String) -> Letter? {
        let lower = transcript
            .trimmingCharacters(in: .whitespacesAndNewlines)
        
        guard !lower.isEmpty else { return nil }
        
        return ArabicAlphabet.all.first { letter in
            lower.contains(letter.symbol) || lower.contains(letter.name)
        }
    }
}

// MARK: - Preview
struct SpeechSandboxView_Previews: PreviewProvider {
    static var previews: some View {
        SpeechSandboxView()
    }
}
